---
title: "ARCap: Collecting High-quality Human Demonstrations for Robot Learning with Augmented Reality Feedback"
collection: publications
permalink: /publication/arcap
excerpt: 'Scaling up robot datat collection with high quality human data'
date: 2024-07-15
venue: 'IEEE ICRA'
paperurl: 'https://arxiv.org/abs/2410.08464'
citation: 'S. Chen, C. Wang, K, Nguyen, L, Fei-Fei, C.K Liu. (2024). &quotARCap: Collecting High-quality Human Demonstrations for Robot Learning with Augmented Reality Feedback. &quot; <i>RSS</i>.'
---
### Abstract
Recent progress in imitation learning from human demonstrations has shown promising results in teaching robots manipulation skills. To further scale up training datasets, recent works start to use portable data collection devices without the need for physical robot hardware. However, due to the absence of on-robot feedback during data collection, the data quality depends heavily on user expertise, and many devices are limited to specific robot embodiments. We propose ARCap, a portable data collection system that provides visual feedback through augmented reality (AR) and haptic warnings to guide users in collecting high-quality demonstrations. Through extensive user studies, we show that ARCap enables novice users to collect robot-executable data that matches robot kinematics and avoids collisions with the scenes. With data collected from ARCap, robots can perform challenging tasks, such as manipulation in cluttered environments and long-horizon cross-embodiment manipulation. ARCap is fully open-source and easy to calibrate; all components are built from off-the-shelf products.

![Fast forward video](/images/arcap.mp4)

[Paper](https://arxiv.org/abs/2410.08464)
[Website](https://stanford-tml.github.io/ARCap/)
[Code](https://github.com/Ericcsr/ARCap)